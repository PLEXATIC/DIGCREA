{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK98gR4bMbB_",
        "outputId": "988463a9-ae2c-4f6d-9e9b-74a3030af6f1"
      },
      "outputs": [],
      "source": [
        "# Initial installation/preparation steps. Only need to be run once per environment.\n",
        "!pip install librosa boto3 requests tqdm opencv-python torch nltk pytorch_pretrained_biggan tensorflow-addons ftfy\n",
        "!git clone https://github.com/huggingface/pytorch-pretrained-BigGAN.git # Get biggan repo\n",
        "\n",
        "# If used on a GPU environment, make sure to not install default pytorch but pytorch for cuda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OuUwwRLNkjv",
        "outputId": "e4227863-6a59-4679-8e11-bc0bd1c77017"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/huggingface/pytorch-pretrained-BigGAN.git # Get biggan repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcsKXwftRxlJ",
        "outputId": "4c82557c-2186-420e-c46d-82708d09ed38"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/divamgupta/stable-diffusion-tensorflow #get Stable diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH0TbpNkYliC"
      },
      "outputs": [],
      "source": [
        "#move files\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "source = '/content/stable-diffusion-tensorflow'\n",
        "destination = '/content'\n",
        " \n",
        "# gather all files\n",
        "allfiles = os.listdir(source)\n",
        " \n",
        "# iterate on all files to move them to destination folder\n",
        "for f in allfiles:\n",
        "    src_path = os.path.join(source, f)\n",
        "    dst_path = os.path.join(destination, f)\n",
        "    shutil.move(src_path, dst_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrZQ8RTjbT7z"
      },
      "outputs": [],
      "source": [
        "#delete old folder\n",
        "os.rmdir(source)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnCI5UetMbCD",
        "outputId": "f6bea5b1-6673-45c6-8dd3-0ea4926b2c94"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "import cv2 as cv\n",
        "import librosa\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "sys.path.append(\"./pytorch-pretrained-BigGAN\")\n",
        "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample)\n",
        "from stable_diffusion_tf.stable_diffusion import StableDiffusion\n",
        "from PIL import Image\n",
        "\n",
        "model = BigGAN.from_pretrained('biggan-deep-512')\n",
        "truncation = 0.5\n",
        "nltk.download('wordnet')\n",
        "class_labels = ['soap bubble', \"eagle\", \"goldfish\"]\n",
        "nltk.download('omw-1.4')\n",
        "class_vector = one_hot_from_names(class_labels, batch_size=len(class_labels))\n",
        "noise_vector = truncated_noise_sample(truncation=(truncation * 3), batch_size=1)\n",
        "print(noise_vector.shape)\n",
        "model.to('cuda')\n",
        "# Noise shape is 128\n",
        "\n",
        "filename = \"sound.mp3\"\n",
        "sound_data, sampling_rate = librosa.load(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erCV11wvMbCE",
        "outputId": "aba760a2-4994-4a8e-8db4-53a8e7c53911"
      },
      "outputs": [],
      "source": [
        "seconds = len(sound_data)/sampling_rate\n",
        "video_frame_count = int(seconds*30)\n",
        "samples_per_frame = int(sampling_rate/30)\n",
        "\n",
        "frequency_samples = []\n",
        "max_db = 0\n",
        "for i in range(0, sound_data.shape[0]-samples_per_frame, samples_per_frame):\n",
        "    X = np.fft.rfft(sound_data[i:samples_per_frame+i])\n",
        "    Xdb = 20*np.log10(np.abs(X))\n",
        "    frequency_samples.append(np.nan_to_num(Xdb, nan=0, posinf=50, neginf=-50))\n",
        "frequency_samples = np.array(frequency_samples)\n",
        "max_db = np.max(frequency_samples)\n",
        "frequency_samples /= max_db\n",
        "print(max_db)\n",
        "frequency_samples.shape, video_frame_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTEBT2GEMbCF"
      },
      "outputs": [],
      "source": [
        "max_frequencies = np.max(frequency_samples)\n",
        "min_frequency = np.min(frequency_samples)\n",
        "normed_frequencies = (frequency_samples-min_frequency)/(np.max(max_frequencies)-min_frequency)\n",
        "pca = KernelPCA(n_components=128, kernel=\"rbf\", gamma=0.1)\n",
        "\n",
        "transformed = pca.fit_transform(normed_frequencies)\n",
        "\n",
        "t_max = np.max(transformed)\n",
        "t_min = np.min(transformed)\n",
        "transformed = (transformed-t_min)/(t_max-t_min)\n",
        "transformed -= np.mean(transformed, axis=0)\n",
        "transformed *= 2\n",
        "\n",
        "low_frequencies = transformed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yk_EZkj2MbCF",
        "outputId": "91c2abcf-ea01-4248-dd28-c643797b71cf"
      },
      "outputs": [],
      "source": [
        "frames_per_class = video_frame_count//(len(class_labels)-1)\n",
        "classes_from = class_vector[:-1]\n",
        "classes_to = class_vector[1:]\n",
        "\n",
        "i = 0\n",
        "images = []\n",
        "for class_from, class_to in zip(classes_from, classes_to):\n",
        "    interpolations = np.linspace(class_from, class_to, frames_per_class)\n",
        "    for interpolation in interpolations:\n",
        "        noise_vector += low_frequencies[i]*0.9\n",
        "        noise_vector = np.clip(noise_vector, -1, 1)\n",
        "        noise_vector *= 0.9\n",
        "        i += 1\n",
        "        torch_noise = torch.from_numpy(np.float32(noise_vector))\n",
        "        torch_noise = torch_noise.to('cuda')\n",
        "        torch_class = torch.from_numpy(np.array([interpolation]))\n",
        "        torch_class = torch_class.to('cuda')\n",
        "        with torch.no_grad():\n",
        "            output = model(torch_noise, torch_class, truncation)\n",
        "            output = output.to(\"cpu\")\n",
        "            img = output[0]\n",
        "        np_img = img.permute(1, 2, 0).numpy()\n",
        "        img_max = np.max(np_img)\n",
        "        img_min = np.min(np_img)\n",
        "        np_img = (np_img - img_min) / (img_max - img_min)\n",
        "        images.append(img)\n",
        "        print(i)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CCw61ltMbCH"
      },
      "outputs": [],
      "source": [
        "rgb_images = []\n",
        "for img in images:\n",
        "    img = img.permute(1, 2, 0).numpy()\n",
        "    max_val = np.max(img)\n",
        "    min_val = np.min(img)\n",
        "    img = (img - min_val) / (max_val - min_val)\n",
        "    #scale img to 512x512\n",
        "    img = cv.resize(img, (512, 512))\n",
        "    #append output to list\n",
        "    rgb_images.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_txmW5hbfOvC"
      },
      "outputs": [],
      "source": [
        "generator = StableDiffusion(\n",
        "img_height=512,\n",
        "img_width=512,\n",
        "jit_compile=False,  # You can try True as well (different performance profile)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEXBOiHJXjFa"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P73PTVAIRL1B",
        "outputId": "ad3a7753-7f2d-41e3-93d3-debb7d479a04"
      },
      "outputs": [],
      "source": [
        "#create video\n",
        "video_writer = cv.VideoWriter('sound_walk.avi', cv.VideoWriter_fourcc(*'MJPG'), 30, (512, 512))\n",
        "sd_img = []\n",
        "\n",
        "for img in rgb_images[:100]:\n",
        "  img = img * 255\n",
        "  img = cv.cvtColor(img, cv.COLOR_RGB2BGR)\n",
        "  print(np.max(img))\n",
        "  #create stable diffusion img\n",
        "  img = generator.generate(\n",
        "      seed=42,\n",
        "      prompt=\"LSD\",\n",
        "      num_steps=3,\n",
        "      unconditional_guidance_scale=0,\n",
        "      temperature=0.5,\n",
        "      batch_size=1,\n",
        "      input_image=img,\n",
        "      input_image_strength=0.999\n",
        "  )\n",
        "\n",
        "  video_writer.write((img * 255).astype(np.uint8))\n",
        "  sd_img.append((img * 255))\n",
        "\n",
        "  pil_img = Image.fromarray(img[0])\n",
        "  display(pil_img)\n",
        "\n",
        "video_writer.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VH08pRnoMgCN"
      },
      "outputs": [],
      "source": [
        "from moviepy.editor import *\n",
        "videoclip = VideoFileClip(\"sound_walk.avi\")\n",
        "audioclip = AudioFileClip(\"sound.mp3\")\n",
        "\n",
        "new_audioclip = CompositeAudioClip([audioclip])\n",
        "videoclip.audio = new_audioclip\n",
        "videoclip.write_videofile(\"sound_walk_new.mp4\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.8 ('biggan')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "b155296571072bd54c2824da18a7ef4f2515166210c8b4334a37fe2dd1c52dbc"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
