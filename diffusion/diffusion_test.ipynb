{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyoD9PBmPxNZ",
        "outputId": "44d47333-91f7-40e3-e464-1343113ef0ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.7/dist-packages (4.6.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.0.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.3.5.1)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.21.6)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.10.2)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.8.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (5.10.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (4.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (1.24.3)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->tensorflow_datasets) (3.9.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.56.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras_cv in /usr/local/lib/python3.7/dist-packages (0.3.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras_cv) (21.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from keras_cv) (2022.6.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from keras_cv) (1.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras_cv) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "!pip install tensorflow_datasets\n",
        "!pip install keras_cv\n",
        "!pip install sklearn\n",
        "import keras_cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAxllVXvR-XK",
        "outputId": "72e6e43f-2695-444e-ef3f-849d77ff0100"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "By using this model checkpoint, you acknowledge that its usage is subject to the terms of the CreativeML Open RAIL-M license at https://raw.githubusercontent.com/CompVis/stable-diffusion/main/LICENSE\n"
          ]
        }
      ],
      "source": [
        "model = keras_cv.models.StableDiffusion(jit_compile=False)\n",
        "encoding_1 = model.encode_text(\"Photo of an astronaut riding a horse\")\n",
        "encoding_2 = model.encode_text(\"Photo of a lion surfing on a wave, octane render, realistic, cinematic, focused, sharp, epic, beautiful, vibrant\")\n",
        "\n",
        "seed = 12345\n",
        "noise = tf.random.normal((512 // 8, 512 // 8, 4), seed=seed)\n",
        "noise2 = tf.random.normal((512 // 8, 512 // 8, 4), seed=seed)\n",
        "quality = 10\n",
        "\n",
        "def recursive_distance_walk(model, encoding_1, encoding_2, max_frame_distance=0.1, p1=0, p2=1, img1=None, img2=None):\n",
        "    global seed, noise, quality    \n",
        "\n",
        "    if img1 is None:\n",
        "        image_1 = model.generate_image(\n",
        "            encoding_1,\n",
        "            batch_size=1,\n",
        "            diffusion_noise=noise,\n",
        "            num_steps=quality\n",
        "        )\n",
        "        cv.imwrite(f\"image_at{p1}.png\", cv.cvtColor(image_1[0], cv.COLOR_RGB2BGR))\n",
        "    else:\n",
        "        image_1 = img1\n",
        "\n",
        "    if img2 is None:\n",
        "        image_2 = model.generate_image(\n",
        "            encoding_2,\n",
        "            batch_size=1,\n",
        "            diffusion_noise=noise,\n",
        "            num_steps=quality\n",
        "        )\n",
        "        cv.imwrite(f\"image_at{p2}.png\", cv.cvtColor(image_2[0], cv.COLOR_RGB2BGR))\n",
        "    else:\n",
        "        image_2 = img2\n",
        "\n",
        "    #distance = np.linalg.norm((image_1 - image_2)/255.0)\n",
        "\n",
        "    plt.imshow(image_1[0])\n",
        "    plt.show()\n",
        "    plt.imshow(image_2[0])\n",
        "    plt.show()\n",
        "\n",
        "    similarity = 0\n",
        "    comats = []\n",
        "    for i in range(image_1[0].shape[2]):\n",
        "        diff =  (image_1[0][:, :, i])/255.0 - (image_2[0][:, :, i])/255.0\n",
        "        \n",
        "        sobel_x1 = cv.Sobel((image_1[0][:, :, i])/255.0, -1, 1, 0, 3)\n",
        "        sobel_y1 = cv.Sobel((image_1[0][:, :, i])/255.0, -1, 0, 1, 3)\n",
        "\n",
        "        edges_1 = (sobel_x1**2 + sobel_y1**2)\n",
        "\n",
        "        sobel_x2 = cv.Sobel((image_2[0][:, :, i])/255.0, -1, 1, 0, 3)\n",
        "        sobel_y2 = cv.Sobel((image_2[0][:, :, i])/255.0, -1, 0, 1, 3)\n",
        "        edges_2 = sobel_x2**2 + sobel_y2**2\n",
        "        \n",
        "        diff_2 = (edges_1 - edges_2)**2\n",
        "        similarity += np.sum(diff_2)\n",
        "        comats.append(diff_2)\n",
        "    print(similarity)\n",
        "    plt.imshow(np.stack(comats, axis=-1)*100)\n",
        "    plt.show()\n",
        "\n",
        "    p3 = 0.5*(p1 + p2)\n",
        "\n",
        "    if similarity < max_frame_distance:\n",
        "        return [image_1, image_2]\n",
        "    else:\n",
        "        middle_encoding = (encoding_1 + encoding_2) / 2.0\n",
        "        return recursive_distance_walk(model, encoding_1, middle_encoding, max_frame_distance, img1=image_1, p1=p1, p2=p3) + recursive_distance_walk(model, middle_encoding, encoding_2, max_frame_distance, img2=image_2, p1=p3, p2=p2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7666eMjks9v"
      },
      "outputs": [],
      "source": [
        "class PointRepresentation(object):\n",
        "  def __init__(self, image, embedding, linear_position, noise):\n",
        "    self.image = image\n",
        "    self.embedding = embedding\n",
        "    self.linear_position = linear_position\n",
        "    self.noise = noise\n",
        "\n",
        "  def get_image_distance(self, other):\n",
        "    distance = 0\n",
        "    for i in range(self.image.shape[2]):\n",
        "        sobel_x1 = cv.Sobel((self.image[:, :, i])/255.0, -1, 1, 0, 3)\n",
        "        sobel_y1 = cv.Sobel((self.image[:, :, i])/255.0, -1, 0, 1, 3)\n",
        "\n",
        "        edges_1 = (sobel_x1**2 + sobel_y1**2)\n",
        "\n",
        "        sobel_x2 = cv.Sobel((other.image[:, :, i])/255.0, -1, 1, 0, 3)\n",
        "        sobel_y2 = cv.Sobel((other.image[:, :, i])/255.0, -1, 0, 1, 3)\n",
        "        edges_2 = sobel_x2**2 + sobel_y2**2\n",
        "        \n",
        "        diff = (self.image[:, :, i])/255.0 - (other.image[:, :, i])/255.0\n",
        "        diff = diff**2\n",
        "\n",
        "        diff_2 = (edges_1 - edges_2)**2\n",
        "        distance += np.sum(diff_2) + 0.01*np.sum(diff)\n",
        "    return distance\n",
        "\n",
        "  def get_mix(self, other, factor):\n",
        "    new_embedding = other.embedding*factor + (1-factor)*self.embedding\n",
        "    new_linear_position = other.linear_position * factor + (1-factor) * self.linear_position\n",
        "    new_noise = other.noise * factor + (1-factor) * self.noise\n",
        "    new_point = PointRepresentation(None, new_embedding, new_linear_position, new_noise)\n",
        "    return new_point\n",
        "\n",
        "\n",
        "class NbestInterpolationsFinder(object):\n",
        "  def __init__(self, model, n, noise, noise2, embedding_start, embedding_end, quality=10):\n",
        "    self.model = model\n",
        "    self.n = n\n",
        "    self.noise = noise\n",
        "    self.noise2 = noise2\n",
        "    self.embedding_start = embedding_start\n",
        "    self.embedding_end = embedding_end\n",
        "    self.quality = quality\n",
        "\n",
        "  def calculate_images(self):\n",
        "    representations = [PointRepresentation(None, self.embedding_start, 0, self.noise), PointRepresentation(None, self.embedding_end, 1, self.noise2)]\n",
        "\n",
        "    for representation in representations:\n",
        "      image = self.model.generate_image(\n",
        "          representation.embedding,\n",
        "          batch_size=1,\n",
        "          diffusion_noise=representation.noise,\n",
        "          num_steps=self.quality\n",
        "      )\n",
        "      representation.image = image[0] \n",
        "\n",
        "    while(len(representations) < self.n):\n",
        "      list_b = representations[1:]\n",
        "      list_a = representations[:-1]\n",
        "\n",
        "      biggest_distance = 0\n",
        "      worst_area = representations\n",
        "      for a, b in zip(list_a, list_b):\n",
        "        dist = a.get_image_distance(b)\n",
        "        if dist > biggest_distance:\n",
        "          biggest_distance = dist\n",
        "          worst_area = [a, b]\n",
        "      print(\"Worst distance was: \" )\n",
        "      print(biggest_distance)\n",
        "      self.sample_at(worst_area, representations)\n",
        "    return representations\n",
        "\n",
        "  def sample_at(self, area, representations):\n",
        "    point_a, point_b = area[0], area[1]\n",
        "    middle_point = point_a.get_mix(point_b, 0.5)\n",
        "\n",
        "    image = self.model.generate_image(\n",
        "            middle_point.embedding,\n",
        "            batch_size=1,\n",
        "            diffusion_noise=middle_point.noise,\n",
        "            num_steps=self.quality\n",
        "        )\n",
        "    \n",
        "    middle_point.image = image[0]\n",
        "    insertion_index = representations.index(point_a)+1\n",
        "    representations.insert(insertion_index, middle_point)\n",
        "\n",
        "\n",
        "class TextToVideo(object):\n",
        "  def __init__(self, model, texts, noise_function, steps_per_image=10, steps_per_prompt=300):\n",
        "    self.model = model\n",
        "    self.texts = texts\n",
        "    self.noise_function = noise_function\n",
        "    self.steps_per_image = steps_per_image\n",
        "    self.steps_per_prompt = steps_per_prompt\n",
        "\n",
        "  def generate_video(self):\n",
        "    video_images = []\n",
        "    encodings = [self.model.encode_text(text) for text in self.texts]\n",
        "    alist = encodings[:-1]\n",
        "    blist = encodings[1:]\n",
        "    for encoding_a, encoding_b in zip(alist, blist):\n",
        "      best_interpolation_finder = NbestInterpolationsFinder(self.model, self.steps_per_prompt, self.noise_function(0), self.noise_function(0), encoding_a, encoding_b, quality=self.steps_per_image)\n",
        "      part_images = best_interpolation_finder.calculate_images()\n",
        "      video_images += part_images\n",
        "    return video_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiIm3HtPWIF5",
        "outputId": "4b370461-2133-46ae-fe45-026a3369fb5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 28s 1s/step\n",
            "10/10 [==============================] - 11s 1s/step\n",
            "Worst distance was: \n",
            "305947.87916224997\n",
            "10/10 [==============================] - 11s 1s/step\n",
            "Worst distance was: \n",
            "266484.6724185097\n",
            "10/10 [==============================] - 11s 1s/step\n",
            "Worst distance was: \n",
            "266192.77345827717\n",
            "10/10 [==============================] - 11s 1s/step\n",
            "Worst distance was: \n",
            "264702.0424257637\n",
            "10/10 [==============================] - 11s 1s/step\n",
            "Worst distance was: \n",
            "209206.34592630283\n",
            "10/10 [==============================] - 11s 1s/step\n",
            "Worst distance was: \n",
            "176321.80992403967\n",
            "10/10 [==============================] - 11s 1s/step\n",
            "Worst distance was: \n",
            "119121.67625105714\n",
            "10/10 [==============================] - 11s 1s/step\n",
            "Worst distance was: \n",
            "99967.75759962527\n",
            "10/10 [==============================] - 11s 1s/step\n",
            "Worst distance was: \n",
            "96511.13941672556\n",
            "10/10 [==============================] - 11s 1s/step\n",
            "Worst distance was: \n",
            "94061.99184653204\n",
            " 7/10 [====================>.........] - ETA: 3s"
          ]
        }
      ],
      "source": [
        "step_index = 0\n",
        "texts = [\n",
        "  \"\",\n",
        "  \"\"\n",
        "]\n",
        "noise = tf.random.normal((512 // 8, 512 // 8, 4), seed=seed)\n",
        "def noise_func(x):\n",
        "  global noise\n",
        "  return noise\n",
        "\n",
        "ttv = TextToVideo(model, texts, noise_func, steps_per_prompt=100)\n",
        "video = ttv.generate_video()\n",
        "#nbip = NbestInterpolationsFinder(model, 60*5, noise, noise2, encoding_1, encoding_1, quality=50)\n",
        "for img in video:\n",
        "  plt.imshow(img)\n",
        "  plt.show()\n",
        "  cv.imwrite(f\"walk_step_{step_index}.png\", cv.cvtColor(img, cv.COLOR_RGB2BGR))\n",
        "  step_index += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbjpT0zFIlu2"
      },
      "outputs": [],
      "source": [
        "#step_index = 0\n",
        "#for img in recursive_distance_walk(model, encoding_1, encoding_2, max_frame_distance=10000):\n",
        "#  plt.imshow(img[0])\n",
        "#  plt.show()\n",
        "#  cv.imwrite(f\"walk_step_{step_index}.png\", cv.cvtColor(img[0], cv.COLOR_RGB2BGR))\n",
        "#  step_index += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-qBQOtiPIMV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def load_images():\n",
        "    images = []\n",
        "    names = os.listdir(\"./\")\n",
        "    valid_names = [name for name in names if name.startswith(\"walk_step_\")]\n",
        "    names = valid_names\n",
        "    for name in sorted(names, key=lambda x: int(x.split(\"_\")[2].split(\".\")[0])):\n",
        "        if name.startswith(\"walk_step_\"):\n",
        "            images.append(cv.imread(name))\n",
        "    return images\n",
        "\n",
        "def export_as_gif(filename, images, frames_per_second=10, rubber_band=False):\n",
        "    if rubber_band:\n",
        "        images += images[2:-1][::-1]\n",
        "    images[0].save(\n",
        "        filename,\n",
        "        save_all=True,\n",
        "        append_images=images[1:],\n",
        "        duration=1000 // frames_per_second,\n",
        "        loop=0,\n",
        "    )\n",
        "\n",
        "\n",
        "export_as_gif(\n",
        "    \"Dragon-astronaut.gif\",\n",
        "    [Image.fromarray(cv.cvtColor(img, cv.COLOR_BGR2RGB)) for img in load_images()],\n",
        "    frames_per_second=30,\n",
        "    rubber_band=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTS4U7tPR-XM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "a9b33701161aa344749724b060d75b05bdd9f55dde0b12b625fe683d97d26887"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
