{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK98gR4bMbB_",
        "outputId": "cb0bed48-bde6-4f45-d82c-7c71e4eea1b5"
      },
      "outputs": [],
      "source": [
        "# Initial installation/preparation steps. Only need to be run once per environment.\n",
        "!pip install librosa boto3 requests tqdm opencv-python torch nltk pytorch_pretrained_biggan tensorflow-addons ftfy ffmpeg-python\n",
        "!git clone https://github.com/huggingface/pytorch-pretrained-BigGAN.git # Get biggan repo\n",
        "\n",
        "# If used on a GPU environment, make sure to not install default pytorch but pytorch for cuda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OuUwwRLNkjv"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/huggingface/pytorch-pretrained-BigGAN.git # Get biggan repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcsKXwftRxlJ",
        "outputId": "8b308b28-6270-4a90-d37a-6e4322023485"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/PLEXATIC/stable-diffusion-tensorflow-digcrea #get Stable diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH0TbpNkYliC"
      },
      "outputs": [],
      "source": [
        "#move files\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "source = '/content/stable-diffusion-tensorflow-digcrea'\n",
        "destination = '/content'\n",
        " \n",
        "# gather all files\n",
        "allfiles = os.listdir(source)\n",
        " \n",
        "# iterate on all files to move them to destination folder\n",
        "for f in allfiles:\n",
        "    src_path = os.path.join(source, f)\n",
        "    dst_path = os.path.join(destination, f)\n",
        "    shutil.move(src_path, dst_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrZQ8RTjbT7z"
      },
      "outputs": [],
      "source": [
        "#delete old folder\n",
        "os.rmdir(source)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnCI5UetMbCD",
        "outputId": "8244a9d6-2273-4a16-b3d9-a0243a0718b1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "import cv2 as cv\n",
        "import librosa\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "sys.path.append(\"./pytorch-pretrained-BigGAN\")\n",
        "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample)\n",
        "from stable_diffusion_tf.stable_diffusion import StableDiffusion\n",
        "from PIL import Image\n",
        "import math\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKt22AHplOOV"
      },
      "outputs": [],
      "source": [
        "truncation = 0.35\n",
        "extra_detail = 0.6 # Higher Value = more detail. valid range: [0;1[\n",
        "max_frequency_level = 11000 # All Frequencies higher than this will not be considered.\n",
        "low_frequency_skip = 16 # skip the first n herz\n",
        "frequency_band_growth_rate = 1.015\n",
        "smoothing_factor = 0.1 # How much the noise will be smothened. 0 = no smoothing, 1 = full smoothing\n",
        "iterations = 2 # How many times to apply the smoothing algorithm. Higher value = more smoothing\n",
        "debug = False # wether or not to display the weights for the weighted sum at each timestep.\n",
        "\n",
        "# Free and royalty free music form pixabay.com\n",
        "class_labels = ['soap bubble', \"mushroom\"] # List of labels from imagenet. See https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a for a full list.\n",
        "filename = \"sound.wav\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkZ9l_uoDIA1"
      },
      "outputs": [],
      "source": [
        "model = BigGAN.from_pretrained('biggan-deep-512')\n",
        "class_vector = one_hot_from_names(class_labels, batch_size=len(class_labels))\n",
        "model.to('cuda')\n",
        "# Noise shape is 128\n",
        "\n",
        "sound_data, sampling_rate = librosa.load(filename, sr=None)\n",
        "\n",
        "sound_data = sound_data[:sampling_rate * 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqa4r79VDkS8"
      },
      "outputs": [],
      "source": [
        "seconds = len(sound_data)/sampling_rate\n",
        "video_frame_count = int(math.ceil(seconds*30))\n",
        "step_size = int(math.ceil(sampling_rate/30))\n",
        "samples_per_frame = sampling_rate\n",
        "#samples_per_frame = step_size * 5\n",
        "\n",
        "softmax_rep_factors = [1]\n",
        "\n",
        "def softmax(x):\n",
        "    return np.exp(x)/sum(np.exp(x))\n",
        "\n",
        "frequency_samples = []\n",
        "smoothing_level = 1\n",
        "for i in range(0, sound_data.shape[0]-(samples_per_frame+smoothing_level), step_size):\n",
        "    X = np.fft.rfft(sound_data[i:samples_per_frame+i])\n",
        "    Xdb = 20*np.log10(np.abs(X))\n",
        "    db_sum = np.sum(Xdb)\n",
        "    top_n_freqs = np.zeros_like(Xdb)\n",
        "    softmax_xdb = Xdb.copy()\n",
        "    for softmax_factor in softmax_rep_factors:\n",
        "        softmax_xdb = softmax(softmax_xdb)\n",
        "        top_n_freqs += softmax_xdb * softmax_factor\n",
        "        softmax_xdb[np.argmax(softmax_xdb)] = -10e3\n",
        "    Xdb = top_n_freqs\n",
        "    Xdb = Xdb ** (1-extra_detail)\n",
        "    biggest_prob_index = np.argmax(Xdb)\n",
        "    biggest_probability = Xdb[biggest_prob_index]\n",
        "    frequency_sums = []\n",
        "    sum_range = 10\n",
        "    precise_sum_range = 1.0\n",
        "    sum_start = low_frequency_skip\n",
        "    max_freq = min(max_frequency_level, sampling_rate//2)\n",
        "    sum_increment = frequency_band_growth_rate\n",
        "    while sum_range*sum_increment + sum_start < max_freq:\n",
        "        precise_sum_range *= sum_increment\n",
        "        sum_range = int(precise_sum_range)\n",
        "        new_index = sum_start + sum_range\n",
        "        if len(Xdb[sum_start:new_index]) > 1:\n",
        "            frequency_sums.append(np.mean(Xdb[sum_start:new_index]))\n",
        "        sum_start = new_index\n",
        "    frequency_samples.append(np.nan_to_num(np.array(frequency_sums), nan=0, posinf=50, neginf=-50))\n",
        "frequency_samples = np.array(frequency_samples)\n",
        "\n",
        "#Smoothing the noise\n",
        "noise_vector = truncated_noise_sample(truncation=truncation, batch_size=frequency_samples.shape[1])\n",
        "reference_noise = noise_vector[0]\n",
        "original_noises = []\n",
        "for i in range(len(noise_vector)):\n",
        "    original_noises.append(noise_vector[i])\n",
        "sorted_noises = []\n",
        "\n",
        "while len(sorted_noises) < len(noise_vector):\n",
        "    # Use the correlation of x and reference_noise as measure\n",
        "    distances = []\n",
        "    for x in original_noises:\n",
        "        correlation = np.corrcoef(reference_noise, x)[0,1]\n",
        "        distances.append(correlation)\n",
        "    closest_noise_index = np.argmin(distances)\n",
        "\n",
        "    sorted_noises.append(original_noises[closest_noise_index])\n",
        "    reference_noise = original_noises.pop(closest_noise_index)\n",
        "noise_vector = sorted_noises\n",
        "\n",
        "for _ in range(iterations):\n",
        "    for i in range(1, len(noise_vector)):\n",
        "        noise_vector[i] = noise_vector[i-1] * smoothing_factor + noise_vector[i] * (1-smoothing_factor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeGvCfLNDuQM",
        "outputId": "c35c5294-92ae-4c48-826d-31fc29350a02"
      },
      "outputs": [],
      "source": [
        "## Actually generate biggan video\n",
        "frames_per_class = video_frame_count//(len(class_labels)-1)\n",
        "classes_from = class_vector[:-1]\n",
        "classes_to = class_vector[1:]\n",
        "\n",
        "i = 0\n",
        "images = []\n",
        "for class_from, class_to in zip(classes_from, classes_to):\n",
        "    interpolations = np.linspace(class_from, class_to, frames_per_class)\n",
        "    for interpolation in interpolations:\n",
        "        if i >= len(frequency_samples):\n",
        "            break\n",
        "        interpolation_factors = frequency_samples[i]\n",
        "        # Take weighted sum of noise vectors using interpolation factors\n",
        "        \n",
        "        final_noise = np.zeros_like(noise_vector[0])\n",
        "        for _, interpolation_factor in enumerate(interpolation_factors):\n",
        "            final_noise += noise_vector[_] * interpolation_factor\n",
        "        noise_vec = np.clip(final_noise, -1, 1)\n",
        "        #noise_vec = torch.from_numpy(noise_vec).unsqueeze(0).to('cuda')\n",
        "        i += 1\n",
        "        torch_noise = torch.from_numpy(np.float32(noise_vec)).unsqueeze(0)\n",
        "        torch_noise = torch_noise.to('cuda')\n",
        "        torch_class = torch.from_numpy(np.array([interpolation]))\n",
        "        torch_class = torch_class.to('cuda')\n",
        "        with torch.no_grad():\n",
        "            output = model(torch_noise, torch_class, truncation)\n",
        "            output = output.to(\"cpu\")\n",
        "            img = output[0]\n",
        "        np_img = img.permute(1, 2, 0).numpy()\n",
        "        img_max = np.max(np_img)\n",
        "        img_min = np.min(np_img)\n",
        "        np_img = (np_img - img_min) / (img_max - img_min)\n",
        "        images.append(img)\n",
        "        print(i/len(frequency_samples))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CCw61ltMbCH"
      },
      "outputs": [],
      "source": [
        "rgb_images = []\n",
        "for img in images:\n",
        "    img = img.permute(1, 2, 0).numpy()\n",
        "    max_val = np.max(img)\n",
        "    min_val = np.min(img)\n",
        "    img = (img - min_val) / (max_val - min_val)\n",
        "    img = cv.resize(img, (512, 512))\n",
        "    rgb_images.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_txmW5hbfOvC"
      },
      "outputs": [],
      "source": [
        "generator = StableDiffusion(\n",
        "img_height=512,\n",
        "img_width=512,\n",
        "jit_compile=False,  # You can try True as well (different performance profile)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEXBOiHJXjFa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P73PTVAIRL1B",
        "outputId": "b7964e09-49a4-4d77-bee6-63d3bc785e67"
      },
      "outputs": [],
      "source": [
        "#create video\n",
        "video_writer = cv.VideoWriter('sound_walk.avi', cv.VideoWriter_fourcc(*'MJPG'), 30, (512, 512))\n",
        "sd_img = []\n",
        "\n",
        "interpolation_steps = 5\n",
        "interpolation_factors = np.linspace(0, 1, interpolation_steps)\n",
        "previous_img = None\n",
        "try:\n",
        "    for img in tqdm(rgb_images[::interpolation_steps]):\n",
        "        img = img * 255.0\n",
        "        #create stable diffusion img\n",
        "        img = generator.generate(\n",
        "            seed=42,\n",
        "            prompt=\"Photorealistic, epic, focused, sharp, cinematic lighting, 4k, 8k, octane rendering, legendary, fantasy, trippy, LSD\",\n",
        "            num_steps=10,\n",
        "            unconditional_guidance_scale=7.5,\n",
        "            temperature=0.0,\n",
        "            batch_size=1,\n",
        "            input_image=img,\n",
        "            input_image_strength=0.5\n",
        "        )[0]\n",
        "        pil_img = Image.fromarray(img)\n",
        "        display(pil_img)\n",
        "        img = cv.cvtColor(img, cv.COLOR_RGB2BGR)\n",
        "    \n",
        "        if previous_img is not None and interpolation_steps > 1:\n",
        "            for f in interpolation_factors[1:]:\n",
        "                interpolated_image = f*img + (1-f)*previous_img\n",
        "                interpolated_image = np.zeros_like(img)\n",
        "                for c in range(interpolated_image.shape[-1]):\n",
        "                    interpolated_image[:, :, c] = f*img[:, :, c] + (1-f)*previous_img[:, :, c]\n",
        "                #interpolated_image[:, :, c] = np.clip(interpolated_image[:, :, c], 0.0, 1.0)\n",
        "                video_writer.write(-(interpolated_image * 255).astype(np.uint8))\n",
        "        previous_img = img.copy()\n",
        "        video_writer.write(-(img * 255).astype(np.uint8))\n",
        "        sd_img.append((img * 255))\n",
        "except:\n",
        "    print(\"interrupted or failed\")\n",
        "video_writer.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH08pRnoMgCN",
        "outputId": "a12f6bc0-e5f2-43ce-c3d5-ba4ea38bc5cb"
      },
      "outputs": [],
      "source": [
        "import ffmpeg\n",
        "import os\n",
        "input_video = ffmpeg.input('sound_walk.avi')\n",
        "input_audio = ffmpeg.input('sound.wav')\n",
        "result_name = \"final_result_n.mp4\"\n",
        "if os.path.exists(result_name):\n",
        "    os.remove(result_name)\n",
        "ffmpeg.concat(input_video, input_audio, v=1, a=1).output(result_name).run()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
