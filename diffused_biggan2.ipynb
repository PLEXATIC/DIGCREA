{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK98gR4bMbB_",
        "outputId": "cb0bed48-bde6-4f45-d82c-7c71e4eea1b5"
      },
      "outputs": [],
      "source": [
        "# Initial installation/preparation steps. Only need to be run once per environment.\n",
        "!pip install librosa boto3 requests tqdm opencv-python torch nltk pytorch_pretrained_biggan tensorflow-addons ftfy\n",
        "!git clone https://github.com/huggingface/pytorch-pretrained-BigGAN.git # Get biggan repo\n",
        "\n",
        "# If used on a GPU environment, make sure to not install default pytorch but pytorch for cuda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OuUwwRLNkjv"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/huggingface/pytorch-pretrained-BigGAN.git # Get biggan repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcsKXwftRxlJ",
        "outputId": "8b308b28-6270-4a90-d37a-6e4322023485"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/PLEXATIC/stable-diffusion-tensorflow-digcrea #get Stable diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH0TbpNkYliC"
      },
      "outputs": [],
      "source": [
        "#move files\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "source = '/content/stable-diffusion-tensorflow'\n",
        "destination = '/content'\n",
        " \n",
        "# gather all files\n",
        "allfiles = os.listdir(source)\n",
        " \n",
        "# iterate on all files to move them to destination folder\n",
        "for f in allfiles:\n",
        "    src_path = os.path.join(source, f)\n",
        "    dst_path = os.path.join(destination, f)\n",
        "    shutil.move(src_path, dst_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrZQ8RTjbT7z"
      },
      "outputs": [],
      "source": [
        "#delete old folder\n",
        "os.rmdir(source)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnCI5UetMbCD",
        "outputId": "e740c490-52db-4433-bd94-9f0812f577bc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "import cv2 as cv\n",
        "import librosa\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "sys.path.append(\"./pytorch-pretrained-BigGAN\")\n",
        "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample)\n",
        "from stable_diffusion_tf.stable_diffusion import StableDiffusion\n",
        "from PIL import Image\n",
        "import math\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKt22AHplOOV"
      },
      "outputs": [],
      "source": [
        "truncation = 0.3\n",
        "extra_detail = 0.6 # Higher Value = more detail. valid range: [0;1[\n",
        "max_frequency_level = 11000 # All Frequencies higher than this will not be considered.\n",
        "low_frequency_skip = 16 # skip the first n herz\n",
        "frequency_band_growth_rate = 1.015\n",
        "smoothing_factor = 0.1 # How much the noise will be smothened. 0 = no smoothing, 1 = full smoothing\n",
        "iterations = 2 # How many times to apply the smoothing algorithm. Higher value = more smoothing\n",
        "debug = False # wether or not to display the weights for the weighted sum at each timestep.\n",
        "\n",
        "# Free and royalty free music form pixabay.com\n",
        "class_labels = ['soap bubble', \"mushroom\"] # List of labels from imagenet. See https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a for a full list.\n",
        "filename = \"sound.wav\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkZ9l_uoDIA1"
      },
      "outputs": [],
      "source": [
        "model = BigGAN.from_pretrained('biggan-deep-512')\n",
        "class_vector = one_hot_from_names(class_labels, batch_size=len(class_labels))\n",
        "model.to('cuda')\n",
        "# Noise shape is 128\n",
        "\n",
        "sound_data, sampling_rate = librosa.load(filename, sr=None)\n",
        "\n",
        "sound_data = sound_data[:sampling_rate * 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqa4r79VDkS8"
      },
      "outputs": [],
      "source": [
        "seconds = len(sound_data)/sampling_rate\n",
        "video_frame_count = int(math.ceil(seconds*30))\n",
        "step_size = int(math.ceil(sampling_rate/30))\n",
        "samples_per_frame = sampling_rate\n",
        "#samples_per_frame = step_size * 5\n",
        "\n",
        "softmax_rep_factors = [1]\n",
        "\n",
        "def softmax(x):\n",
        "    return np.exp(x)/sum(np.exp(x))\n",
        "\n",
        "frequency_samples = []\n",
        "smoothing_level = 1\n",
        "for i in range(0, sound_data.shape[0]-(samples_per_frame+smoothing_level), step_size):\n",
        "    X = np.fft.rfft(sound_data[i:samples_per_frame+i])\n",
        "    Xdb = 20*np.log10(np.abs(X))\n",
        "    db_sum = np.sum(Xdb)\n",
        "    top_n_freqs = np.zeros_like(Xdb)\n",
        "    softmax_xdb = Xdb.copy()\n",
        "    for softmax_factor in softmax_rep_factors:\n",
        "        softmax_xdb = softmax(softmax_xdb)\n",
        "        top_n_freqs += softmax_xdb * softmax_factor\n",
        "        softmax_xdb[np.argmax(softmax_xdb)] = -10e3\n",
        "    Xdb = top_n_freqs\n",
        "    Xdb = Xdb ** (1-extra_detail)\n",
        "    biggest_prob_index = np.argmax(Xdb)\n",
        "    biggest_probability = Xdb[biggest_prob_index]\n",
        "    frequency_sums = []\n",
        "    sum_range = 10\n",
        "    precise_sum_range = 1.0\n",
        "    sum_start = low_frequency_skip\n",
        "    max_freq = min(max_frequency_level, sampling_rate//2)\n",
        "    sum_increment = frequency_band_growth_rate\n",
        "    while sum_range*sum_increment + sum_start < max_freq:\n",
        "        precise_sum_range *= sum_increment\n",
        "        sum_range = int(precise_sum_range)\n",
        "        new_index = sum_start + sum_range\n",
        "        if len(Xdb[sum_start:new_index]) > 1:\n",
        "            frequency_sums.append(np.mean(Xdb[sum_start:new_index]))\n",
        "        sum_start = new_index\n",
        "    frequency_samples.append(np.nan_to_num(np.array(frequency_sums), nan=0, posinf=50, neginf=-50))\n",
        "frequency_samples = np.array(frequency_samples)\n",
        "\n",
        "#Smoothing the noise\n",
        "noise_vector = truncated_noise_sample(truncation=truncation, batch_size=frequency_samples.shape[1])\n",
        "reference_noise = noise_vector[0]\n",
        "original_noises = []\n",
        "for i in range(len(noise_vector)):\n",
        "    original_noises.append(noise_vector[i])\n",
        "sorted_noises = []\n",
        "\n",
        "while len(sorted_noises) < len(noise_vector):\n",
        "    # Use the correlation of x and reference_noise as measure\n",
        "    distances = []\n",
        "    for x in original_noises:\n",
        "        correlation = np.corrcoef(reference_noise, x)[0,1]\n",
        "        distances.append(correlation)\n",
        "    closest_noise_index = np.argmin(distances)\n",
        "\n",
        "    sorted_noises.append(original_noises[closest_noise_index])\n",
        "    reference_noise = original_noises.pop(closest_noise_index)\n",
        "noise_vector = sorted_noises\n",
        "\n",
        "for _ in range(iterations):\n",
        "    for i in range(1, len(noise_vector)):\n",
        "        noise_vector[i] = noise_vector[i-1] * smoothing_factor + noise_vector[i] * (1-smoothing_factor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeGvCfLNDuQM",
        "outputId": "be8c145a-8d9c-4b96-f9fe-0cbd2248a8f3"
      },
      "outputs": [],
      "source": [
        "## Actually generate biggan video\n",
        "frames_per_class = video_frame_count//(len(class_labels)-1)\n",
        "classes_from = class_vector[:-1]\n",
        "classes_to = class_vector[1:]\n",
        "\n",
        "i = 0\n",
        "images = []\n",
        "for class_from, class_to in zip(classes_from, classes_to):\n",
        "    interpolations = np.linspace(class_from, class_to, frames_per_class)\n",
        "    for interpolation in interpolations:\n",
        "        if i >= len(frequency_samples):\n",
        "            break\n",
        "        interpolation_factors = frequency_samples[i]\n",
        "        # Take weighted sum of noise vectors using interpolation factors\n",
        "        \n",
        "        final_noise = np.zeros_like(noise_vector[0])\n",
        "        for _, interpolation_factor in enumerate(interpolation_factors):\n",
        "            final_noise += noise_vector[_] * interpolation_factor\n",
        "        noise_vec = np.clip(final_noise, -1, 1)\n",
        "        #noise_vec = torch.from_numpy(noise_vec).unsqueeze(0).to('cuda')\n",
        "        i += 1\n",
        "        torch_noise = torch.from_numpy(np.float32(noise_vec)).unsqueeze(0)\n",
        "        torch_noise = torch_noise.to('cuda')\n",
        "        torch_class = torch.from_numpy(np.array([interpolation]))\n",
        "        torch_class = torch_class.to('cuda')\n",
        "        with torch.no_grad():\n",
        "            output = model(torch_noise, torch_class, truncation)\n",
        "            output = output.to(\"cpu\")\n",
        "            img = output[0]\n",
        "        np_img = img.permute(1, 2, 0).numpy()\n",
        "        img_max = np.max(np_img)\n",
        "        img_min = np.min(np_img)\n",
        "        np_img = (np_img - img_min) / (img_max - img_min)\n",
        "        images.append(img)\n",
        "        print(i/len(frequency_samples))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CCw61ltMbCH"
      },
      "outputs": [],
      "source": [
        "rgb_images = []\n",
        "for img in images:\n",
        "    img = img.permute(1, 2, 0).numpy()\n",
        "    max_val = np.max(img)\n",
        "    min_val = np.min(img)\n",
        "    img = (img - min_val) / (max_val - min_val)\n",
        "    img = cv.resize(img, (512, 512))\n",
        "    rgb_images.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_txmW5hbfOvC"
      },
      "outputs": [],
      "source": [
        "generator = StableDiffusion(\n",
        "img_height=512,\n",
        "img_width=512,\n",
        "jit_compile=False,  # You can try True as well (different performance profile)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEXBOiHJXjFa"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "QRcF1M8DHddM",
        "outputId": "5d985b32-cff0-40bf-9e5f-2d37765134c9"
      },
      "outputs": [],
      "source": [
        "plt.imshow(rgb_images[1]-rgb_images[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P73PTVAIRL1B",
        "outputId": "acb79bba-7253-442d-9926-c7c13d7ae17c"
      },
      "outputs": [],
      "source": [
        "#create video\n",
        "video_writer = cv.VideoWriter('sound_walk.avi', cv.VideoWriter_fourcc(*'MJPG'), 30, (512, 512))\n",
        "sd_img = []\n",
        "\n",
        "for img in rgb_images[:3]:\n",
        "  img = img * 255.0\n",
        "  #create stable diffusion img\n",
        "  img = generator.generate(\n",
        "      seed=42,\n",
        "      prompt=\"Photorealistic, epic, focused, sharp, cinematic lighting\",\n",
        "      num_steps=10,\n",
        "      unconditional_guidance_scale=10,\n",
        "      temperature=0.0,\n",
        "      batch_size=1,\n",
        "      input_image=img,\n",
        "      input_image_strength=0.9\n",
        "  )[0]\n",
        "  pil_img = Image.fromarray(img)\n",
        "  display(pil_img)\n",
        "\n",
        "  img = cv.cvtColor(img, cv.COLOR_RGB2BGR)\n",
        "  video_writer.write(255-(img * 255).astype(np.uint8))\n",
        "  sd_img.append((img * 255))\n",
        "\n",
        "video_writer.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbnO9xfKKKVI",
        "outputId": "f96f4e72-1aae-4730-e9cf-091e5a24d6b9"
      },
      "outputs": [],
      "source": [
        "!pip install ffmpeg-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH08pRnoMgCN",
        "outputId": "385df1c5-df3d-410b-8d39-9a3f7b009590"
      },
      "outputs": [],
      "source": [
        "import ffmpeg\n",
        "import os\n",
        "input_video = ffmpeg.input('sound_walk.avi')\n",
        "input_audio = ffmpeg.input('sound.wav')\n",
        "result_name = \"final_result_n.mp4\"\n",
        "if os.path.exists(result_name):\n",
        "    os.remove(result_name)\n",
        "ffmpeg.concat(input_video, input_audio, v=1, a=1).output(result_name).run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3GFBS7ZKBN3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.8 ('biggan')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "b155296571072bd54c2824da18a7ef4f2515166210c8b4334a37fe2dd1c52dbc"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
