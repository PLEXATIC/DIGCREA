{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK98gR4bMbB_",
        "outputId": "36906da4-12e8-40fb-c94b-bd709b8540de"
      },
      "outputs": [],
      "source": [
        "# Initial installation/preparation steps. Only need to be run once per environment.\n",
        "!pip install librosa boto3 requests tqdm opencv-python torch nltk pytorch_pretrained_biggan tensorflow-addons ftfy ffmpeg-python\n",
        "!git clone https://github.com/huggingface/pytorch-pretrained-BigGAN.git # Get biggan repo\n",
        "\n",
        "# If used on a GPU environment, make sure to not install default pytorch but pytorch for cuda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OuUwwRLNkjv",
        "outputId": "29213e39-999a-4776-d94d-832bc9010e65"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/huggingface/pytorch-pretrained-BigGAN.git # Get biggan repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcsKXwftRxlJ",
        "outputId": "236a15cc-a5c6-4392-deeb-2ce46b7d639b"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/PLEXATIC/stable-diffusion-tensorflow-digcrea #get Stable diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JrpSxfIp5K0N"
      },
      "outputs": [],
      "source": [
        "#@title File Paths\n",
        "\n",
        "#@markdown ## Please upload a music file and enter the file Path to it:\n",
        "music_input_path = \"/content/newsound.mp3\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ## Please add your desired Output:\n",
        "video_output_path = \"/content/newsound_out.mp4\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH0TbpNkYliC"
      },
      "outputs": [],
      "source": [
        "#move files\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "source = '/content/stable-diffusion-tensorflow-digcrea'\n",
        "destination = '/content'\n",
        " \n",
        "# gather all files\n",
        "allfiles = os.listdir(source)\n",
        " \n",
        "# iterate on all files to move them to destination folder\n",
        "for f in allfiles:\n",
        "    src_path = os.path.join(source, f)\n",
        "    dst_path = os.path.join(destination, f)\n",
        "    shutil.move(src_path, dst_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrZQ8RTjbT7z"
      },
      "outputs": [],
      "source": [
        "#delete old folder\n",
        "os.rmdir(source)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnCI5UetMbCD",
        "outputId": "c55e59bc-09de-4897-9233-9f177ddcc59c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "import cv2 as cv\n",
        "import librosa\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "sys.path.append(\"./pytorch-pretrained-BigGAN\")\n",
        "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample)\n",
        "from stable_diffusion_tf.stable_diffusion import StableDiffusion\n",
        "from PIL import Image\n",
        "import math\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-B4VOHb5Pmu"
      },
      "outputs": [],
      "source": [
        "#@title Biggan Values\n",
        "#@markdown ## Please add some [Biggan Labels](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a)\n",
        "#@markdown #### Please add your values separated by pipe character in format: \" | \" (space pipe space)\n",
        "labels = 'teapot | bubble | mushroom' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Truncation\n",
        "trunc = 0.35 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Extra Detail\n",
        "#@markdown #### Higher Value = more detail. valid range: [0;1[\n",
        "ed = 0.6 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Maximum Frequency Level\n",
        "#@markdown ####  All Frequencies higher than this will not be considered.\n",
        "mfl = 4292 #@param {type:\"slider\", min:0, max:20000, step:1}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Low Frequency Skip\n",
        "#@markdown #### Skip the first n herz\n",
        "lfs = 16 #@param {type:\"slider\", min:0, max:10000, step:1}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Frequency Band Growth Rate\n",
        "fbgr = 1.015 #@param {type:\"slider\", min:1.0001, max:2, step:0.0001}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Smoothing Factor\n",
        "#@markdown #### How many times to apply the smoothing algorithm. Higher value = more smoothing\n",
        "sf = 0.34 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Iterations\n",
        "#@markdown #### How many times to apply the smoothing algorithm. Higher value = more smoothing\n",
        "iters = 2 #@param {type:\"slider\", min:0, max:10, step:1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKt22AHplOOV"
      },
      "outputs": [],
      "source": [
        "truncation = float(trunc)\n",
        "extra_detail = float(ed) # Higher Value = more detail. valid range: [0;1[\n",
        "max_frequency_level = int(mfl) # All Frequencies higher than this will not be considered.\n",
        "low_frequency_skip = int(lfs) # skip the first n herz\n",
        "frequency_band_growth_rate = float(fbgr)\n",
        "smoothing_factor = float(sf) # How much the noise will be smothened. 0 = no smoothing, 1 = full smoothing\n",
        "iterations = iters # How many times to apply the smoothing algorithm. Higher value = more smoothing\n",
        "debug = False # wether or not to display the weights for the weighted sum at each timestep.\n",
        "\n",
        "# Free and royalty free music form pixabay.com\n",
        "class_labels = labels.split(' | ') # List of labels from imagenet. See https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a for a full list.\n",
        "filename = music_input_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkZ9l_uoDIA1",
        "outputId": "ef4dd0f4-b945-4a1a-c5e6-5b611d2fc2a7"
      },
      "outputs": [],
      "source": [
        "model = BigGAN.from_pretrained('biggan-deep-512')\n",
        "class_vector = one_hot_from_names(class_labels, batch_size=len(class_labels))\n",
        "model.to('cuda')\n",
        "# Noise shape is 128\n",
        "\n",
        "sound_data, sampling_rate = librosa.load(filename, sr=None)\n",
        "\n",
        "sound_data = sound_data[:sampling_rate * 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqa4r79VDkS8"
      },
      "outputs": [],
      "source": [
        "seconds = len(sound_data)/sampling_rate\n",
        "video_frame_count = int(math.ceil(seconds*30))\n",
        "step_size = int(math.ceil(sampling_rate/30))\n",
        "samples_per_frame = sampling_rate\n",
        "#samples_per_frame = step_size * 5\n",
        "\n",
        "softmax_rep_factors = [1]\n",
        "\n",
        "def softmax(x):\n",
        "    return np.exp(x)/sum(np.exp(x))\n",
        "\n",
        "frequency_samples = []\n",
        "smoothing_level = 1\n",
        "for i in range(0, sound_data.shape[0]-(samples_per_frame+smoothing_level), step_size):\n",
        "    X = np.fft.rfft(sound_data[i:samples_per_frame+i])\n",
        "    Xdb = 20*np.log10(np.abs(X))\n",
        "    db_sum = np.sum(Xdb)\n",
        "    top_n_freqs = np.zeros_like(Xdb)\n",
        "    softmax_xdb = Xdb.copy()\n",
        "    for softmax_factor in softmax_rep_factors:\n",
        "        softmax_xdb = softmax(softmax_xdb)\n",
        "        top_n_freqs += softmax_xdb * softmax_factor\n",
        "        softmax_xdb[np.argmax(softmax_xdb)] = -10e3\n",
        "    Xdb = top_n_freqs\n",
        "    Xdb = Xdb ** (1-extra_detail)\n",
        "    biggest_prob_index = np.argmax(Xdb)\n",
        "    biggest_probability = Xdb[biggest_prob_index]\n",
        "    frequency_sums = []\n",
        "    sum_range = 10\n",
        "    precise_sum_range = 1.0\n",
        "    sum_start = low_frequency_skip\n",
        "    max_freq = min(max_frequency_level, sampling_rate//2)\n",
        "    sum_increment = frequency_band_growth_rate\n",
        "    while sum_range*sum_increment + sum_start < max_freq:\n",
        "        precise_sum_range *= sum_increment\n",
        "        sum_range = int(precise_sum_range)\n",
        "        new_index = sum_start + sum_range\n",
        "        if len(Xdb[sum_start:new_index]) > 1:\n",
        "            frequency_sums.append(np.mean(Xdb[sum_start:new_index]))\n",
        "        sum_start = new_index\n",
        "    frequency_samples.append(np.nan_to_num(np.array(frequency_sums), nan=0, posinf=50, neginf=-50))\n",
        "frequency_samples = np.array(frequency_samples)\n",
        "\n",
        "#Smoothing the noise\n",
        "noise_vector = truncated_noise_sample(truncation=truncation, batch_size=frequency_samples.shape[1])\n",
        "reference_noise = noise_vector[0]\n",
        "original_noises = []\n",
        "for i in range(len(noise_vector)):\n",
        "    original_noises.append(noise_vector[i])\n",
        "sorted_noises = []\n",
        "\n",
        "while len(sorted_noises) < len(noise_vector):\n",
        "    # Use the correlation of x and reference_noise as measure\n",
        "    distances = []\n",
        "    for x in original_noises:\n",
        "        correlation = np.corrcoef(reference_noise, x)[0,1]\n",
        "        distances.append(correlation)\n",
        "    closest_noise_index = np.argmin(distances)\n",
        "\n",
        "    sorted_noises.append(original_noises[closest_noise_index])\n",
        "    reference_noise = original_noises.pop(closest_noise_index)\n",
        "noise_vector = sorted_noises\n",
        "\n",
        "for _ in range(iterations):\n",
        "    for i in range(1, len(noise_vector)):\n",
        "        noise_vector[i] = noise_vector[i-1] * smoothing_factor + noise_vector[i] * (1-smoothing_factor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeGvCfLNDuQM",
        "outputId": "2c2460e3-df05-43af-963f-2d9dbfd7b244"
      },
      "outputs": [],
      "source": [
        "## Actually generate biggan video\n",
        "frames_per_class = video_frame_count//(len(class_labels)-1)\n",
        "classes_from = class_vector[:-1]\n",
        "classes_to = class_vector[1:]\n",
        "\n",
        "i = 0\n",
        "images = []\n",
        "for class_from, class_to in zip(classes_from, classes_to):\n",
        "    interpolations = np.linspace(class_from, class_to, frames_per_class)\n",
        "    for interpolation in interpolations:\n",
        "        if i >= len(frequency_samples):\n",
        "            break\n",
        "        interpolation_factors = frequency_samples[i]\n",
        "        # Take weighted sum of noise vectors using interpolation factors\n",
        "        \n",
        "        final_noise = np.zeros_like(noise_vector[0])\n",
        "        for _, interpolation_factor in enumerate(interpolation_factors):\n",
        "            final_noise += noise_vector[_] * interpolation_factor\n",
        "        noise_vec = np.clip(final_noise, -1, 1)\n",
        "        #noise_vec = torch.from_numpy(noise_vec).unsqueeze(0).to('cuda')\n",
        "        i += 1\n",
        "        torch_noise = torch.from_numpy(np.float32(noise_vec)).unsqueeze(0)\n",
        "        torch_noise = torch_noise.to('cuda')\n",
        "        torch_class = torch.from_numpy(np.array([interpolation]))\n",
        "        torch_class = torch_class.to('cuda')\n",
        "        with torch.no_grad():\n",
        "            output = model(torch_noise, torch_class, truncation)\n",
        "            output = output.to(\"cpu\")\n",
        "            img = output[0]\n",
        "        np_img = img.permute(1, 2, 0).numpy()\n",
        "        img_max = np.max(np_img)\n",
        "        img_min = np.min(np_img)\n",
        "        np_img = (np_img - img_min) / (img_max - img_min)\n",
        "        images.append(img)\n",
        "        print(i/len(frequency_samples))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CCw61ltMbCH"
      },
      "outputs": [],
      "source": [
        "rgb_images = []\n",
        "for img in images:\n",
        "    img = img.permute(1, 2, 0).numpy()\n",
        "    max_val = np.max(img)\n",
        "    min_val = np.min(img)\n",
        "    img = (img - min_val) / (max_val - min_val)\n",
        "    img = cv.resize(img, (512, 512))\n",
        "    rgb_images.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_txmW5hbfOvC",
        "outputId": "e18fa26d-8d19-48da-e5c4-3f05394fc1ce"
      },
      "outputs": [],
      "source": [
        "generator = StableDiffusion(\n",
        "img_height=512,\n",
        "img_width=512,\n",
        "jit_compile=False,  # You can try True as well (different performance profile)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEXBOiHJXjFa"
      },
      "outputs": [],
      "source": [
        "#@title Stable Diffusion Values\n",
        "\n",
        "#@markdown ## Add prompt for Stable Diffusion\n",
        "prompt_in = 'Photorealistic, epic, focused, sharp, cinematic lighting, 4k, 8k, octane rendering' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Number of interpolation steps\n",
        "interpolation_steps = 10 #@param {type:\"slider\", min:2, max:10, step:1}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Number of steps to generate the image\n",
        "num_steps = 2 #@param {type:\"slider\", min:1, max:100, step:1}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Unconditional guiding Scale\n",
        "ugs = 7.5 #@param {type:\"slider\", min:0, max:10, step:0.1}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Input Image strength\n",
        "#@markdown #### How much the output differs from the input image\n",
        "iis=0.5 #@param {type:\"slider\", min:0, max:1, step:0.01}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P73PTVAIRL1B",
        "outputId": "30f664c7-6356-4a40-8078-e227a5be5469"
      },
      "outputs": [],
      "source": [
        "#create video\n",
        "video_writer = cv.VideoWriter('sound_walk.avi', cv.VideoWriter_fourcc(*'MJPG'), 30, (512, 512))\n",
        "sd_img = []\n",
        "\n",
        "interpolation_factors = np.linspace(0, 1, interpolation_steps+2)\n",
        "previous_img = None\n",
        "try:\n",
        "    for img in tqdm(rgb_images[::interpolation_steps+1]):\n",
        "        img = img * 255.0\n",
        "        #create stable diffusion img\n",
        "        img = generator.generate(\n",
        "            seed=42,\n",
        "            prompt=prompt_in,\n",
        "            num_steps=num_steps,\n",
        "            unconditional_guidance_scale=ugs,\n",
        "            temperature=0.0,\n",
        "            batch_size=1,\n",
        "            input_image=img,\n",
        "            input_image_strength=iis\n",
        "        )[0]\n",
        "        pil_img = Image.fromarray(img)\n",
        "        display(pil_img)\n",
        "        img = cv.cvtColor(img, cv.COLOR_RGB2BGR)\n",
        "    \n",
        "        if previous_img is not None and interpolation_steps > 0:\n",
        "            for f in interpolation_factors[1:-1]:\n",
        "                interpolated_image = f*img + (1-f)*previous_img\n",
        "                interpolated_image = np.zeros_like(img)\n",
        "                for c in range(interpolated_image.shape[-1]):\n",
        "                    interpolated_image[:, :, c] = f*img[:, :, c] + (1-f)*previous_img[:, :, c]\n",
        "                #interpolated_image[:, :, c] = np.clip(interpolated_image[:, :, c], 0.0, 1.0)\n",
        "                video_writer.write(-(interpolated_image * 255).astype(np.uint8))\n",
        "        previous_img = img.copy()\n",
        "        video_writer.write(-(img * 255).astype(np.uint8))\n",
        "        sd_img.append((img * 255))\n",
        "except:\n",
        "    print(\"interrupted or failed\")\n",
        "video_writer.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH08pRnoMgCN",
        "outputId": "33cd4b16-ee15-488b-ea0f-d19b1fd2bdb2"
      },
      "outputs": [],
      "source": [
        "import ffmpeg\n",
        "import os\n",
        "input_video = ffmpeg.input('sound_walk.avi')\n",
        "input_audio = ffmpeg.input(music_input_path)\n",
        "result_name = video_output_path\n",
        "if os.path.exists(result_name):\n",
        "    os.remove(result_name)\n",
        "ffmpeg.concat(input_video, input_audio, v=1, a=1).output(result_name).run()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
