{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK98gR4bMbB_",
        "outputId": "36906da4-12e8-40fb-c94b-bd709b8540de"
      },
      "outputs": [],
      "source": [
        "# Initial installation/preparation steps. Only need to be run once per environment.\n",
        "!pip install librosa boto3 requests tqdm opencv-python torch nltk pytorch_pretrained_biggan tensorflow-addons ftfy ffmpeg-python matplotlib\n",
        "\n",
        "# Get biggan repo\n",
        "!git clone https://github.com/huggingface/pytorch-pretrained-BigGAN.git \n",
        "\n",
        "#get Stable diffusion\n",
        "!git clone https://github.com/PLEXATIC/stable-diffusion-tensorflow-digcrea\n",
        "\n",
        "# If used on a GPU environment, make sure to not install default pytorch but pytorch for cuda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JrpSxfIp5K0N"
      },
      "outputs": [],
      "source": [
        "#@title File Paths\n",
        "\n",
        "#@markdown ## Please upload a music file and enter the file Path to it:\n",
        "music_input_path = \"/content/musicfile_in.mp3\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ## Please add your desired Output:\n",
        "video_output_path = \"/content/video_out.mp4\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH0TbpNkYliC"
      },
      "outputs": [],
      "source": [
        "#move files\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "source = '/content/stable-diffusion-tensorflow-digcrea'\n",
        "destination = '/content'\n",
        " \n",
        "# gather all files\n",
        "allfiles = os.listdir(source)\n",
        " \n",
        "# iterate on all files to move them to destination folder\n",
        "try:\n",
        "    for f in allfiles:\n",
        "        src_path = os.path.join(source, f)\n",
        "        dst_path = os.path.join(destination, f)\n",
        "        shutil.move(src_path, dst_path)\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    print(\"This is probably fine and you can move on. This happens if this code block is run multiple times.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrZQ8RTjbT7z"
      },
      "outputs": [],
      "source": [
        "#delete old folder\n",
        "try:\n",
        "    os.rmdir(source)\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnCI5UetMbCD",
        "outputId": "c55e59bc-09de-4897-9233-9f177ddcc59c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "import cv2 as cv\n",
        "import librosa\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "sys.path.append(\"./pytorch-pretrained-BigGAN\")\n",
        "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample)\n",
        "from stable_diffusion_tf.stable_diffusion import StableDiffusion\n",
        "from PIL import Image\n",
        "import math\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4') # If this fails, just re-run. It's a bug in nltk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-B4VOHb5Pmu"
      },
      "outputs": [],
      "source": [
        "#@title Biggan Values\n",
        "#@markdown ## Please add some [Biggan Labels](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a)\n",
        "#@markdown #### Please add your values separated by pipe character in format: \" | \" (space pipe space)\n",
        "labels = 'teapot | bubble | mushroom' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Truncation\n",
        "#@markdown #### Vector length that will be used within BigGAN\n",
        "trunc = 0.35 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Extra Detail\n",
        "#@markdown #### Higher Value = more detail. valid range: [0;1[\n",
        "ed = 0.6 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Maximum Frequency Level\n",
        "#@markdown ####  All Frequencies higher than this will not be considered.\n",
        "mfl = 4292 #@param {type:\"slider\", min:0, max:20000, step:1}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Low Frequency Skip\n",
        "#@markdown #### Skip the first n herz\n",
        "lfs = 16 #@param {type:\"slider\", min:0, max:10000, step:1}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Frequency Band Growth Rate\n",
        "#@markdown #### Factor on how much to increase frequency bands\n",
        "fbgr = 1.015 #@param {type:\"slider\", min:1.0001, max:2, step:0.0001}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Smoothing Factor\n",
        "#@markdown #### Defines how the random vectors will be mixed\n",
        "sf = 0.34 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Iterations\n",
        "#@markdown ## Amount of times the smoothing algorithm will be applied\n",
        "iters = 2 #@param {type:\"slider\", min:0, max:10, step:1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKt22AHplOOV"
      },
      "outputs": [],
      "source": [
        "truncation = float(trunc)\n",
        "extra_detail = float(ed) # Higher Value = more detail. valid range: [0;1[\n",
        "max_frequency_level = int(mfl) # All Frequencies higher than this will not be considered.\n",
        "low_frequency_skip = int(lfs) # skip the first n herz\n",
        "frequency_band_growth_rate = float(fbgr)\n",
        "smoothing_factor = float(sf) # How much the noise will be smothened. 0 = no smoothing, 1 = full smoothing\n",
        "iterations = iters # How many times to apply the smoothing algorithm. Higher value = more smoothing\n",
        "debug = False # wether or not to display the weights for the weighted sum at each timestep.\n",
        "\n",
        "# Free and royalty free music form pixabay.com\n",
        "class_labels = labels.split(' | ') # List of labels from imagenet. See https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a for a full list.\n",
        "filename = music_input_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkZ9l_uoDIA1",
        "outputId": "ef4dd0f4-b945-4a1a-c5e6-5b611d2fc2a7"
      },
      "outputs": [],
      "source": [
        "model = BigGAN.from_pretrained('biggan-deep-512')\n",
        "class_vector = one_hot_from_names(class_labels, batch_size=len(class_labels))\n",
        "model.to('cuda')\n",
        "# Noise shape is 128\n",
        "\n",
        "sound_data, sampling_rate = librosa.load(filename, sr=None)\n",
        "\n",
        "#sound_data = sound_data[:sampling_rate * 10] # This can be used to easily shorten the input to 10 seconds. (for testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqa4r79VDkS8"
      },
      "outputs": [],
      "source": [
        "seconds = len(sound_data)/sampling_rate\n",
        "video_frame_count = int(math.ceil(seconds*30))\n",
        "step_size = int(math.ceil(sampling_rate/30))\n",
        "samples_per_frame = sampling_rate\n",
        "#samples_per_frame = step_size * 5\n",
        "\n",
        "softmax_rep_factors = [1]\n",
        "\n",
        "def softmax(x):\n",
        "    return np.exp(x)/sum(np.exp(x))\n",
        "\n",
        "frequency_samples = []\n",
        "smoothing_level = 1\n",
        "for i in range(0, sound_data.shape[0]-(samples_per_frame+smoothing_level), step_size):\n",
        "    X = np.fft.rfft(sound_data[i:samples_per_frame+i])\n",
        "    Xdb = 20*np.log10(np.abs(X))\n",
        "    db_sum = np.sum(Xdb)\n",
        "    top_n_freqs = np.zeros_like(Xdb)\n",
        "    softmax_xdb = Xdb.copy()\n",
        "    for softmax_factor in softmax_rep_factors:\n",
        "        softmax_xdb = softmax(softmax_xdb)\n",
        "        top_n_freqs += softmax_xdb * softmax_factor\n",
        "        softmax_xdb[np.argmax(softmax_xdb)] = -10e3\n",
        "    Xdb = top_n_freqs\n",
        "    Xdb = Xdb ** (1-extra_detail)\n",
        "    biggest_prob_index = np.argmax(Xdb)\n",
        "    biggest_probability = Xdb[biggest_prob_index]\n",
        "    frequency_sums = []\n",
        "    sum_range = 10\n",
        "    precise_sum_range = 1.0\n",
        "    sum_start = low_frequency_skip\n",
        "    max_freq = min(max_frequency_level, sampling_rate//2)\n",
        "    sum_increment = frequency_band_growth_rate\n",
        "    while sum_range*sum_increment + sum_start < max_freq:\n",
        "        precise_sum_range *= sum_increment\n",
        "        sum_range = int(precise_sum_range)\n",
        "        new_index = sum_start + sum_range\n",
        "        if len(Xdb[sum_start:new_index]) > 1:\n",
        "            frequency_sums.append(np.mean(Xdb[sum_start:new_index]))\n",
        "        sum_start = new_index\n",
        "    frequency_samples.append(np.nan_to_num(np.array(frequency_sums), nan=0, posinf=50, neginf=-50))\n",
        "frequency_samples = np.array(frequency_samples)\n",
        "\n",
        "#Smoothing the noise\n",
        "noise_vector = truncated_noise_sample(truncation=truncation, batch_size=frequency_samples.shape[1])\n",
        "reference_noise = noise_vector[0]\n",
        "original_noises = []\n",
        "for i in range(len(noise_vector)):\n",
        "    original_noises.append(noise_vector[i])\n",
        "sorted_noises = []\n",
        "\n",
        "while len(sorted_noises) < len(noise_vector):\n",
        "    # Use the correlation of x and reference_noise as measure\n",
        "    distances = []\n",
        "    for x in original_noises:\n",
        "        correlation = np.corrcoef(reference_noise, x)[0,1]\n",
        "        distances.append(correlation)\n",
        "    closest_noise_index = np.argmin(distances)\n",
        "\n",
        "    sorted_noises.append(original_noises[closest_noise_index])\n",
        "    reference_noise = original_noises.pop(closest_noise_index)\n",
        "noise_vector = sorted_noises\n",
        "\n",
        "for _ in range(iterations):\n",
        "    for i in range(1, len(noise_vector)):\n",
        "        noise_vector[i] = noise_vector[i-1] * smoothing_factor + noise_vector[i] * (1-smoothing_factor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeGvCfLNDuQM",
        "outputId": "2c2460e3-df05-43af-963f-2d9dbfd7b244"
      },
      "outputs": [],
      "source": [
        "## Actually generate biggan video\n",
        "frames_per_class = video_frame_count//(len(class_labels)-1)\n",
        "classes_from = class_vector[:-1]\n",
        "classes_to = class_vector[1:]\n",
        "\n",
        "i = 0\n",
        "images = []\n",
        "for class_from, class_to in zip(classes_from, classes_to):\n",
        "    interpolations = np.linspace(class_from, class_to, frames_per_class)\n",
        "    for interpolation in interpolations:\n",
        "        if i >= len(frequency_samples):\n",
        "            break\n",
        "        interpolation_factors = frequency_samples[i]\n",
        "        # Take weighted sum of noise vectors using interpolation factors\n",
        "        \n",
        "        final_noise = np.zeros_like(noise_vector[0])\n",
        "        for _, interpolation_factor in enumerate(interpolation_factors):\n",
        "            final_noise += noise_vector[_] * interpolation_factor\n",
        "        noise_vec = np.clip(final_noise, -1, 1)\n",
        "        #noise_vec = torch.from_numpy(noise_vec).unsqueeze(0).to('cuda')\n",
        "        i += 1\n",
        "        torch_noise = torch.from_numpy(np.float32(noise_vec)).unsqueeze(0)\n",
        "        torch_noise = torch_noise.to('cuda')\n",
        "        torch_class = torch.from_numpy(np.array([interpolation]))\n",
        "        torch_class = torch_class.to('cuda')\n",
        "        with torch.no_grad():\n",
        "            output = model(torch_noise, torch_class, truncation)\n",
        "            output = output.to(\"cpu\")\n",
        "            img = output[0]\n",
        "        np_img = img.permute(1, 2, 0).numpy()\n",
        "        img_max = np.max(np_img)\n",
        "        img_min = np.min(np_img)\n",
        "        np_img = (np_img - img_min) / (img_max - img_min)\n",
        "        images.append(img)\n",
        "        print(i/len(frequency_samples))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CCw61ltMbCH"
      },
      "outputs": [],
      "source": [
        "rgb_images = []\n",
        "for img in images:\n",
        "    img = img.permute(1, 2, 0).numpy()\n",
        "    max_val = np.max(img)\n",
        "    min_val = np.min(img)\n",
        "    img = (img - min_val) / (max_val - min_val)\n",
        "    img = cv.resize(img, (512, 512))\n",
        "    rgb_images.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_txmW5hbfOvC",
        "outputId": "e18fa26d-8d19-48da-e5c4-3f05394fc1ce"
      },
      "outputs": [],
      "source": [
        "generator = StableDiffusion(\n",
        "img_height=512,\n",
        "img_width=512,\n",
        "jit_compile=False,  # You can try True as well (different performance profile)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEXBOiHJXjFa"
      },
      "outputs": [],
      "source": [
        "#@title Stable Diffusion Values\n",
        "\n",
        "#@markdown ## Add prompt for Stable Diffusion\n",
        "prompt_in = 'Photorealistic, epic, focused, sharp, cinematic lighting, 4k, 8k, octane rendering' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Number of interpolation steps\n",
        "#@markdown #### How many steps we use to interpolate between two images\n",
        "interpolation_steps = 3 #@param {type:\"slider\", min:2, max:10, step:1}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Number of steps to generate the image\n",
        "#@markdown #### How many steps we use to generate the image\n",
        "num_steps = 12 #@param {type:\"slider\", min:1, max:100, step:1}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Unconditional Guidance Scale\n",
        "#@markdown #### How much the image should follow the prompt\n",
        "ugs = 7.5 #@param {type:\"slider\", min:0, max:10, step:0.1}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Input Image strength\n",
        "#@markdown #### How much the output differs from the input image\n",
        "iis=0.5 #@param {type:\"slider\", min:0, max:1, step:0.01}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P73PTVAIRL1B",
        "outputId": "30f664c7-6356-4a40-8078-e227a5be5469"
      },
      "outputs": [],
      "source": [
        "#create video\n",
        "video_writer = cv.VideoWriter('sound_walk.avi', cv.VideoWriter_fourcc(*'MJPG'), 30, (512, 512))\n",
        "sd_img = []\n",
        "\n",
        "interpolation_factors = np.linspace(0, 1, interpolation_steps+2)\n",
        "previous_img = None\n",
        "try:\n",
        "    for img in tqdm(rgb_images[::interpolation_steps+1]):\n",
        "        img = img * 255.0\n",
        "        #create stable diffusion img\n",
        "        img = generator.generate(\n",
        "            seed=42,\n",
        "            prompt=prompt_in,\n",
        "            num_steps=num_steps,\n",
        "            unconditional_guidance_scale=ugs,\n",
        "            temperature=0.0,\n",
        "            batch_size=1,\n",
        "            input_image=img,\n",
        "            input_image_strength=iis\n",
        "        )[0]\n",
        "        pil_img = Image.fromarray(img)\n",
        "        display(pil_img)\n",
        "        img = cv.cvtColor(img, cv.COLOR_RGB2BGR)\n",
        "    \n",
        "        if previous_img is not None and interpolation_steps > 0:\n",
        "            for f in interpolation_factors[1:-1]:\n",
        "                interpolated_image = f*img + (1-f)*previous_img\n",
        "                interpolated_image = np.zeros_like(img)\n",
        "                for c in range(interpolated_image.shape[-1]):\n",
        "                    interpolated_image[:, :, c] = f*img[:, :, c] + (1-f)*previous_img[:, :, c]\n",
        "                #interpolated_image[:, :, c] = np.clip(interpolated_image[:, :, c], 0.0, 1.0)\n",
        "                video_writer.write(-(interpolated_image * 255).astype(np.uint8))\n",
        "        previous_img = img.copy()\n",
        "        video_writer.write(-(img * 255).astype(np.uint8))\n",
        "        sd_img.append((img * 255))\n",
        "except:\n",
        "    print(\"interrupted or failed\")\n",
        "video_writer.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH08pRnoMgCN",
        "outputId": "33cd4b16-ee15-488b-ea0f-d19b1fd2bdb2"
      },
      "outputs": [],
      "source": [
        "import ffmpeg\n",
        "import os\n",
        "input_video = ffmpeg.input('sound_walk.avi')\n",
        "input_audio = ffmpeg.input(music_input_path)\n",
        "result_name = video_output_path\n",
        "if os.path.exists(result_name):\n",
        "    os.remove(result_name)\n",
        "ffmpeg.concat(input_video, input_audio, v=1, a=1).output(result_name).run()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<iframe\n",
        "    width=\"640\"\n",
        "    height=\"480\"\n",
        "    src=\"https://youtube.com/embed/g8sAQJC_OuI&feature=shares\"\n",
        "    frameborder=\"0\"\n",
        "    allow=\"autoplay; encrypted-media\"\n",
        "    allowfullscreen\n",
        ">\n",
        "</iframe>\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
